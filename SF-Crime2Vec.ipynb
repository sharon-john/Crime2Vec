{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#importing and loading all dependencies- functions, packages \n",
    "\n",
    "import pandas as pd \n",
    "import numpy as np \n",
    "import io \n",
    "import gensim, logging \n",
    "\n",
    "logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s',\\\n",
    "    level=logging.INFO) \n",
    "\n",
    "#Credits: getLOS function from co-intern Abhishek Patil\n",
    "\n",
    "def getLOS( df, const_cols=None, only_cols=None, skip_cols=None ):\n",
    "    # if there are columns to skip\n",
    "    if skip_cols is not None:\n",
    "        if set(skip_cols)<set(df.columns.tolist()):\n",
    "            df = df.drop(skip_cols, axis=1)\n",
    "            \n",
    "    # if only specific columns are needed\n",
    "    if only_cols is not None:\n",
    "        df = df[only_cols]\n",
    "    \n",
    "    # if no constant columns specified then use one row as a sentence\n",
    "    if const_cols is None:\n",
    "        # define list of sentences\n",
    "        listOfSentences = []\n",
    "        \n",
    "        # get all the rows of data frame as generator object\n",
    "        rowsGen = df.iterrows()\n",
    "        \n",
    "        # keep adding to this list a sentence(i.e. a row) for every loop\n",
    "        while True:\n",
    "            nextRow = next(rowsGen, None)\n",
    "            if nextRow == None:\n",
    "                break\n",
    "            listOfSentences.append([ str(elem) for elem in nextRow[1].values ])\n",
    "            \n",
    "    # else use the constant columns for each sentence\n",
    "    else:\n",
    "        # define list of sentences\n",
    "        listOfSentences = [[]]\n",
    "        \n",
    "        # get column names from data frame\n",
    "        dfColNames = list(df.columns)\n",
    "        numDFCols = len(dfColNames)\n",
    "        \n",
    "        # number of constant columns\n",
    "        numCCols = len(const_cols)\n",
    "        \n",
    "        # don't progress if const_cols doesn't\n",
    "        #    1. have column names as in the df's column names\n",
    "        #  & 2. have atleast 1 less column names than df's column names\n",
    "        # condition 1 check\n",
    "        if ( len( [elem for elem in const_cols if elem not in dfColNames] ) != 0 ):\n",
    "            print( \"Column names in const_cols parameter not found in provided data frame!\" )\n",
    "            return           \n",
    "        # and condition 2 check\n",
    "        if ( ( numDFCols-numCCols ) <= 1 ):\n",
    "            print( \"To make sentences, have atleast 1 column not in the const_cols parameter!\" )\n",
    "            return\n",
    "        \n",
    "        # get the column indices which are in df's column names but not in const_cols\n",
    "        # need these indices to make the sentences\n",
    "        colsLeft = np.setdiff1d(dfColNames, const_cols)        \n",
    "        cols_left_ind = sorted([ dfColNames.index(elem) for elem in colsLeft ])\n",
    "        \n",
    "        # also get indices for const_cols\n",
    "        const_cols_ind = sorted([ dfColNames.index(elem) for elem in const_cols ])\n",
    "        \n",
    "        # sort the data frame according to the const_cols\n",
    "        # by default ascending is true\n",
    "        df = df.sort_values(const_cols)\n",
    "        \n",
    "        # get all the rows of data frame as generator object\n",
    "        rowsGen = df.iterrows()\n",
    "        \n",
    "        # iterator to go through the loop for indexing\n",
    "        itr = 0\n",
    "        \n",
    "        # define the previous values of constant columns in a list using the first values\n",
    "        prevColsVal = [ df[colName].values[0] for colName in const_cols ]\n",
    "        \n",
    "        # get a sentence for each different month of an year\n",
    "        while True:\n",
    "            nextRow = next(rowsGen, None)\n",
    "            # break when end of data frame's rows\n",
    "            if nextRow == None:\n",
    "                break\n",
    "            \n",
    "            # get the row values\n",
    "            rowValues = list( nextRow[1].values )\n",
    "            \n",
    "            # get the current values for columns in const_cols\n",
    "            # basically index the values from the row we are currently in\n",
    "            curColsVal = [rowValues[ind] for ind in const_cols_ind]\n",
    "            \n",
    "            # if previous and current list values are same add to existing sentence\n",
    "            if (prevColsVal == curColsVal):\n",
    "                listOfSentences[itr].extend( [ str(rowValues[ind]) for ind in cols_left_ind ] )\n",
    "            # else add a new sentence            \n",
    "            else:\n",
    "                listOfSentences.append( [ str(rowValues[ind]) for ind in cols_left_ind ] )            \n",
    "                # increment iterator\n",
    "                itr = itr + 1\n",
    "        \n",
    "            # store current values as previous ones for the next iteration\n",
    "            prevColsVal = curColsVal\n",
    "            \n",
    "    # return a dictionary object of the data frame and the list of sentences\n",
    "    retDObj = { 'DF': df,\n",
    "                'LOS': listOfSentences }\n",
    "        \n",
    "    return retDObj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9:30\n"
     ]
    }
   ],
   "source": [
    "#Function to split date/time into date and time in separate columns \n",
    "\n",
    "def TimeGenerator(Stamp):\n",
    "    NewTime=''\n",
    "    i=8\n",
    "    if (Stamp[8]!=' '):\n",
    "        while (i<len(Stamp)):\n",
    "            NewTime=NewTime+Stamp[i]\n",
    "            i+=1 \n",
    "    \n",
    "    if (Stamp[8]==' ' and Stamp[9]!=' '):\n",
    "        i+=1\n",
    "        while (i<len(Stamp)):\n",
    "            NewTime=NewTime+Stamp[i]\n",
    "            i+=1\n",
    "    return NewTime \n",
    "\n",
    "print (TimeGenerator('12/22/10 9:30')) \n",
    "                \n",
    "#Our time generator function successfully separates the time from the date/time stamp "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Category</th>\n",
       "      <th>PdDistrict</th>\n",
       "      <th>Time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>878044</th>\n",
       "      <td>ROBBERY</td>\n",
       "      <td>TARAVAL</td>\n",
       "      <td>:15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>878045</th>\n",
       "      <td>LARCENY/THEFT</td>\n",
       "      <td>INGLESIDE</td>\n",
       "      <td>:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>878046</th>\n",
       "      <td>LARCENY/THEFT</td>\n",
       "      <td>SOUTHERN</td>\n",
       "      <td>:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>878047</th>\n",
       "      <td>VANDALISM</td>\n",
       "      <td>SOUTHERN</td>\n",
       "      <td>:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>878048</th>\n",
       "      <td>FORGERY/COUNTERFEITING</td>\n",
       "      <td>BAYVIEW</td>\n",
       "      <td>:01</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      Category PdDistrict Time\n",
       "878044                 ROBBERY    TARAVAL  :15\n",
       "878045           LARCENY/THEFT  INGLESIDE  :01\n",
       "878046           LARCENY/THEFT   SOUTHERN  :01\n",
       "878047               VANDALISM   SOUTHERN  :01\n",
       "878048  FORGERY/COUNTERFEITING    BAYVIEW  :01"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Setting up the dataframe for Crime2Vec \n",
    "\n",
    "df=pd.read_csv(\"Desktop/SFtrain.csv\", header=0, delimiter=\",\")  \n",
    "df.drop(df.columns[[2, 5, 6,7, 8]], axis=1, inplace=True) \n",
    "#df['Category'].replace(['WARRANTS', 'OTHER OFFENSES', 'LARCENY/THEFT', 'VEHICLE THEFT', 'VANDALISM',\n",
    "#'NON-CRIMINAL', 'ROBBERY', 'ASSAULT', 'WEAPON LAWS', 'BURGLARY',\n",
    "#'SUSPICIOUS OCC', 'DRUNKENNESS', 'FORGERY/COUNTERFEITING', 'DRUG/NARCOTIC',\n",
    "#'STOLEN PROPERTY', 'SECONDARY CODES', 'TRESPASS', 'MISSING PERSON', 'FRAUD',\n",
    "#'KIDNAPPING', 'RUNAWAY', 'DRIVING UNDER THE INFLUENCE',\n",
    "#'SEX OFFENSES FORCIBLE' ,'PROSTITUTION', 'DISORDERLY CONDUCT', 'ARSON',\n",
    "#'FAMILY OFFENSES', 'LIQUOR LAWS' ,'BRIBERY', 'EMBEZZLEMENT', 'SUICIDE',\n",
    "#'LOITERING' ,'SEX OFFENSES NON FORCIBLE', 'EXTORTION', 'GAMBLING',\n",
    "#'BAD CHECKS', 'TREA', 'RECOVERED VEHICLE', 'PORNOGRAPHY/OBSCENE MAT'],\n",
    "                                              \n",
    "#['VIOLENT', 'NON-VIOLENT', 'NON-VIOLENT', 'NON-VIOLENT', 'NON-VIOLENT', 'NON-VIOLENT', 'VIOLENT', 'VIOLENT', 'VIOLENT', 'VIOLENT', 'NON-VIOLENT', 'NON-VIOLENT', 'NON-VIOLENT', 'NON-VIOLENT', 'NON-VIOLENT', 'NON-VIOLENT', 'NON-VIOLENT', 'VIOLENT', 'NON-VIOLENT', 'VIOLENT', 'NON-VIOLENT', 'NON-VIOLENT', 'VIOLENT', 'NON-VIOLENT', 'NON-VIOLENT', 'VIOLENT', 'NON-VIOLENT', 'NON-VIOLENT', 'NON-VIOLENT', 'NON-VIOLENT', 'VIOLENT', 'NON-VIOLENT', 'NON-VIOLENT', 'VIOLENT', 'NON-VIOLENT', 'NON-VIOLENT', 'NON-VIOLENT', 'NON-VIOLENT', 'NON-VIOLENT'], inplace= True)\n",
    "\n",
    "Time=[] \n",
    "\n",
    "for i in range(len(df['Dates'])):\n",
    "    Vals=TimeGenerator(df['Dates'][i]) \n",
    "    Time.append(Vals) \n",
    "    \n",
    "newDF=pd.DataFrame({'Time': Time}) #List has been converted to a dataframe \n",
    "    \n",
    "df['Time']=newDF.values\n",
    "df.drop(df.columns[[0,2]], axis=1, inplace= True)\n",
    "df.tail() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['VANDALISM', 'BAYVIEW', '8:30']\n",
      "          Category PdDistrict   Time\n",
      "0         WARRANTS   NORTHERN  23:53\n",
      "2   OTHER OFFENSES   NORTHERN  23:33\n",
      "8    LARCENY/THEFT   RICHMOND  23:00\n",
      "9    LARCENY/THEFT    CENTRAL  23:00\n",
      "13   LARCENY/THEFT   NORTHERN  22:06\n"
     ]
    }
   ],
   "source": [
    "#Applying Crime2Vec to the San Francisco Kaggle data set \n",
    "\n",
    "train=df.sample(frac=0.8,random_state=200)\n",
    "test=df.drop(train.index)\n",
    "\n",
    "F=getLOS(train,const_cols=None, only_cols=None, skip_cols=None)  #This gives us the list of sentences to be fed into the word2vec model.   \n",
    "TrainingSentences= F['LOS']   #storing the list of sentences value portion of the dictionary object returned by getLOS \n",
    "print (TrainingSentences[1]) \n",
    "print (test.head()) \n",
    "\n",
    "#TrainingSentences are now ready to be fed into word2vec model for training "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-09-12 13:07:10,206 : INFO : collecting all words and their counts\n",
      "2017-09-12 13:07:10,208 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
      "2017-09-12 13:07:10,226 : INFO : PROGRESS: at sentence #10000, processed 30000 words, keeping 1373 word types\n",
      "2017-09-12 13:07:10,239 : INFO : PROGRESS: at sentence #20000, processed 60000 words, keeping 1512 word types\n",
      "2017-09-12 13:07:10,258 : INFO : PROGRESS: at sentence #30000, processed 90000 words, keeping 1537 word types\n",
      "2017-09-12 13:07:10,281 : INFO : PROGRESS: at sentence #40000, processed 120000 words, keeping 1546 word types\n",
      "2017-09-12 13:07:10,317 : INFO : PROGRESS: at sentence #50000, processed 150000 words, keeping 1546 word types\n",
      "2017-09-12 13:07:10,352 : INFO : PROGRESS: at sentence #60000, processed 180000 words, keeping 1546 word types\n",
      "2017-09-12 13:07:10,389 : INFO : PROGRESS: at sentence #70000, processed 210000 words, keeping 1547 word types\n",
      "2017-09-12 13:07:10,423 : INFO : PROGRESS: at sentence #80000, processed 240000 words, keeping 1547 word types\n",
      "2017-09-12 13:07:10,463 : INFO : PROGRESS: at sentence #90000, processed 270000 words, keeping 1547 word types\n",
      "2017-09-12 13:07:10,511 : INFO : PROGRESS: at sentence #100000, processed 300000 words, keeping 1548 word types\n",
      "2017-09-12 13:07:10,548 : INFO : PROGRESS: at sentence #110000, processed 330000 words, keeping 1548 word types\n",
      "2017-09-12 13:07:10,595 : INFO : PROGRESS: at sentence #120000, processed 360000 words, keeping 1548 word types\n",
      "2017-09-12 13:07:10,630 : INFO : PROGRESS: at sentence #130000, processed 390000 words, keeping 1548 word types\n",
      "2017-09-12 13:07:10,670 : INFO : PROGRESS: at sentence #140000, processed 420000 words, keeping 1548 word types\n",
      "2017-09-12 13:07:10,725 : INFO : PROGRESS: at sentence #150000, processed 450000 words, keeping 1548 word types\n",
      "2017-09-12 13:07:10,753 : INFO : PROGRESS: at sentence #160000, processed 480000 words, keeping 1548 word types\n",
      "2017-09-12 13:07:10,785 : INFO : PROGRESS: at sentence #170000, processed 510000 words, keeping 1548 word types\n",
      "2017-09-12 13:07:10,813 : INFO : PROGRESS: at sentence #180000, processed 540000 words, keeping 1548 word types\n",
      "2017-09-12 13:07:10,844 : INFO : PROGRESS: at sentence #190000, processed 570000 words, keeping 1548 word types\n",
      "2017-09-12 13:07:10,872 : INFO : PROGRESS: at sentence #200000, processed 600000 words, keeping 1548 word types\n",
      "2017-09-12 13:07:10,903 : INFO : PROGRESS: at sentence #210000, processed 630000 words, keeping 1549 word types\n",
      "2017-09-12 13:07:10,919 : INFO : PROGRESS: at sentence #220000, processed 660000 words, keeping 1549 word types\n",
      "2017-09-12 13:07:10,939 : INFO : PROGRESS: at sentence #230000, processed 690000 words, keeping 1549 word types\n",
      "2017-09-12 13:07:10,967 : INFO : PROGRESS: at sentence #240000, processed 720000 words, keeping 1549 word types\n",
      "2017-09-12 13:07:10,999 : INFO : PROGRESS: at sentence #250000, processed 750000 words, keeping 1549 word types\n",
      "2017-09-12 13:07:11,044 : INFO : PROGRESS: at sentence #260000, processed 780000 words, keeping 1549 word types\n",
      "2017-09-12 13:07:11,066 : INFO : PROGRESS: at sentence #270000, processed 810000 words, keeping 1549 word types\n",
      "2017-09-12 13:07:11,095 : INFO : PROGRESS: at sentence #280000, processed 840000 words, keeping 1549 word types\n",
      "2017-09-12 13:07:11,115 : INFO : PROGRESS: at sentence #290000, processed 870000 words, keeping 1549 word types\n",
      "2017-09-12 13:07:11,136 : INFO : PROGRESS: at sentence #300000, processed 900000 words, keeping 1549 word types\n",
      "2017-09-12 13:07:11,161 : INFO : PROGRESS: at sentence #310000, processed 930000 words, keeping 1549 word types\n",
      "2017-09-12 13:07:11,183 : INFO : PROGRESS: at sentence #320000, processed 960000 words, keeping 1549 word types\n",
      "2017-09-12 13:07:11,208 : INFO : PROGRESS: at sentence #330000, processed 990000 words, keeping 1549 word types\n",
      "2017-09-12 13:07:11,228 : INFO : PROGRESS: at sentence #340000, processed 1020000 words, keeping 1549 word types\n",
      "2017-09-12 13:07:11,247 : INFO : PROGRESS: at sentence #350000, processed 1050000 words, keeping 1549 word types\n",
      "2017-09-12 13:07:11,263 : INFO : PROGRESS: at sentence #360000, processed 1080000 words, keeping 1549 word types\n",
      "2017-09-12 13:07:11,281 : INFO : PROGRESS: at sentence #370000, processed 1110000 words, keeping 1549 word types\n",
      "2017-09-12 13:07:11,307 : INFO : PROGRESS: at sentence #380000, processed 1140000 words, keeping 1549 word types\n",
      "2017-09-12 13:07:11,330 : INFO : PROGRESS: at sentence #390000, processed 1170000 words, keeping 1549 word types\n",
      "2017-09-12 13:07:11,351 : INFO : PROGRESS: at sentence #400000, processed 1200000 words, keeping 1549 word types\n",
      "2017-09-12 13:07:11,382 : INFO : PROGRESS: at sentence #410000, processed 1230000 words, keeping 1549 word types\n",
      "2017-09-12 13:07:11,411 : INFO : PROGRESS: at sentence #420000, processed 1260000 words, keeping 1549 word types\n",
      "2017-09-12 13:07:11,437 : INFO : PROGRESS: at sentence #430000, processed 1290000 words, keeping 1549 word types\n",
      "2017-09-12 13:07:11,459 : INFO : PROGRESS: at sentence #440000, processed 1320000 words, keeping 1549 word types\n",
      "2017-09-12 13:07:11,478 : INFO : PROGRESS: at sentence #450000, processed 1350000 words, keeping 1549 word types\n",
      "2017-09-12 13:07:11,495 : INFO : PROGRESS: at sentence #460000, processed 1380000 words, keeping 1549 word types\n",
      "2017-09-12 13:07:11,512 : INFO : PROGRESS: at sentence #470000, processed 1410000 words, keeping 1549 word types\n",
      "2017-09-12 13:07:11,528 : INFO : PROGRESS: at sentence #480000, processed 1440000 words, keeping 1549 word types\n",
      "2017-09-12 13:07:11,545 : INFO : PROGRESS: at sentence #490000, processed 1470000 words, keeping 1549 word types\n",
      "2017-09-12 13:07:11,560 : INFO : PROGRESS: at sentence #500000, processed 1500000 words, keeping 1549 word types\n",
      "2017-09-12 13:07:11,575 : INFO : PROGRESS: at sentence #510000, processed 1530000 words, keeping 1549 word types\n",
      "2017-09-12 13:07:11,590 : INFO : PROGRESS: at sentence #520000, processed 1560000 words, keeping 1549 word types\n",
      "2017-09-12 13:07:11,606 : INFO : PROGRESS: at sentence #530000, processed 1590000 words, keeping 1549 word types\n",
      "2017-09-12 13:07:11,621 : INFO : PROGRESS: at sentence #540000, processed 1620000 words, keeping 1549 word types\n",
      "2017-09-12 13:07:11,633 : INFO : PROGRESS: at sentence #550000, processed 1650000 words, keeping 1549 word types\n",
      "2017-09-12 13:07:11,646 : INFO : PROGRESS: at sentence #560000, processed 1680000 words, keeping 1549 word types\n",
      "2017-09-12 13:07:11,658 : INFO : PROGRESS: at sentence #570000, processed 1710000 words, keeping 1549 word types\n",
      "2017-09-12 13:07:11,672 : INFO : PROGRESS: at sentence #580000, processed 1740000 words, keeping 1549 word types\n",
      "2017-09-12 13:07:11,688 : INFO : PROGRESS: at sentence #590000, processed 1770000 words, keeping 1549 word types\n",
      "2017-09-12 13:07:11,703 : INFO : PROGRESS: at sentence #600000, processed 1800000 words, keeping 1549 word types\n",
      "2017-09-12 13:07:11,720 : INFO : PROGRESS: at sentence #610000, processed 1830000 words, keeping 1549 word types\n",
      "2017-09-12 13:07:11,738 : INFO : PROGRESS: at sentence #620000, processed 1860000 words, keeping 1549 word types\n",
      "2017-09-12 13:07:11,758 : INFO : PROGRESS: at sentence #630000, processed 1890000 words, keeping 1549 word types\n",
      "2017-09-12 13:07:11,774 : INFO : PROGRESS: at sentence #640000, processed 1920000 words, keeping 1549 word types\n",
      "2017-09-12 13:07:11,789 : INFO : PROGRESS: at sentence #650000, processed 1950000 words, keeping 1549 word types\n",
      "2017-09-12 13:07:11,810 : INFO : PROGRESS: at sentence #660000, processed 1980000 words, keeping 1549 word types\n",
      "2017-09-12 13:07:11,831 : INFO : PROGRESS: at sentence #670000, processed 2010000 words, keeping 1549 word types\n",
      "2017-09-12 13:07:11,850 : INFO : PROGRESS: at sentence #680000, processed 2040000 words, keeping 1549 word types\n",
      "2017-09-12 13:07:11,873 : INFO : PROGRESS: at sentence #690000, processed 2070000 words, keeping 1549 word types\n",
      "2017-09-12 13:07:11,895 : INFO : PROGRESS: at sentence #700000, processed 2100000 words, keeping 1549 word types\n",
      "2017-09-12 13:07:11,900 : INFO : collected 1549 word types from a corpus of 2107317 raw words and 702439 sentences\n",
      "2017-09-12 13:07:11,902 : INFO : Loading a fresh vocabulary\n",
      "2017-09-12 13:07:11,911 : INFO : min_count=5 retains 1548 unique words (99% of original 1549, drops 1)\n",
      "2017-09-12 13:07:11,913 : INFO : min_count=5 leaves 2107314 word corpus (99% of original 2107317, drops 3)\n",
      "2017-09-12 13:07:11,923 : INFO : deleting the raw counts dictionary of 1549 items\n",
      "2017-09-12 13:07:11,927 : INFO : sample=0.001 downsamples 50 most-common words\n",
      "2017-09-12 13:07:11,930 : INFO : downsampling leaves estimated 988398 word corpus (46.9% of prior 2107314)\n",
      "2017-09-12 13:07:11,931 : INFO : estimated required memory for 1548 words and 300 dimensions: 4489200 bytes\n",
      "2017-09-12 13:07:11,941 : INFO : resetting layer weights\n",
      "2017-09-12 13:07:11,982 : INFO : training model with 3 workers on 1548 vocabulary and 300 features, using sg=1 hs=0 sample=0.001 negative=5 window=500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary successfully built!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-09-12 13:07:13,007 : INFO : PROGRESS: at 8.73% examples, 427799 words/s, in_qsize 4, out_qsize 1\n",
      "2017-09-12 13:07:14,011 : INFO : PROGRESS: at 17.46% examples, 428800 words/s, in_qsize 4, out_qsize 2\n",
      "2017-09-12 13:07:15,014 : INFO : PROGRESS: at 26.19% examples, 429147 words/s, in_qsize 5, out_qsize 0\n",
      "2017-09-12 13:07:16,021 : INFO : PROGRESS: at 33.97% examples, 417405 words/s, in_qsize 6, out_qsize 0\n",
      "2017-09-12 13:07:17,056 : INFO : PROGRESS: at 41.76% examples, 407833 words/s, in_qsize 6, out_qsize 0\n",
      "2017-09-12 13:07:18,061 : INFO : PROGRESS: at 48.49% examples, 395153 words/s, in_qsize 4, out_qsize 1\n",
      "2017-09-12 13:07:19,068 : INFO : PROGRESS: at 57.03% examples, 398568 words/s, in_qsize 6, out_qsize 0\n",
      "2017-09-12 13:07:20,081 : INFO : PROGRESS: at 65.67% examples, 401442 words/s, in_qsize 4, out_qsize 1\n",
      "2017-09-12 13:07:21,097 : INFO : PROGRESS: at 74.02% examples, 402043 words/s, in_qsize 4, out_qsize 2\n",
      "2017-09-12 13:07:22,105 : INFO : PROGRESS: at 82.28% examples, 402260 words/s, in_qsize 4, out_qsize 1\n",
      "2017-09-12 13:07:23,106 : INFO : PROGRESS: at 89.77% examples, 399375 words/s, in_qsize 5, out_qsize 1\n",
      "2017-09-12 13:07:24,114 : INFO : PROGRESS: at 98.22% examples, 400645 words/s, in_qsize 5, out_qsize 0\n",
      "2017-09-12 13:07:24,300 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2017-09-12 13:07:24,302 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2017-09-12 13:07:24,304 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2017-09-12 13:07:24,305 : INFO : training on 10536585 raw words (4940792 effective words) took 12.3s, 401537 effective words/s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "4940792"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Train Crime2Vec \n",
    "\n",
    "from gensim.models import Word2Vec\n",
    "\n",
    "model = gensim.models.Word2Vec(min_count=5, window=500, size=300, workers=3, sg=1, negative=5)       # an empty model, no training\n",
    "model.build_vocab(TrainingSentences)  #1-pass step to build vocab\n",
    "print (\"Vocabulary successfully built!\")  \n",
    "model.train(TrainingSentences, total_examples=model.corpus_count,epochs=model.iter) #1 pass step to train model\n",
    "\n",
    "#The model's vocabulary has been built and the model has now been trained on the corpus as well "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['NORTHERN', '23:33']\n"
     ]
    }
   ],
   "source": [
    "tester=test.copy() \n",
    "tester.drop(tester.columns[[0]], axis=1, inplace=True) \n",
    "\n",
    "G=getLOS(tester,const_cols=None, only_cols=None, skip_cols=None)  #This gives us the list of sentences to be fed into the word2vec model.   \n",
    "TestSentences=G['LOS'] \n",
    "print (TestSentences[1])  \n",
    "\n",
    "#TestingSentences are now ready to be fed into the accuracy tester for testing "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('PROSTITUTION', 0.0079189623), ('STOLEN PROPERTY', 0.0072257756), ('DRUNKENNESS', 0.0068500256), ('TRESPASS', 0.0068101063), ('DISORDERLY CONDUCT', 0.00622604), ('DRIVING UNDER THE INFLUENCE', 0.0055827266), ('WEAPON LAWS', 0.0052899709), ('LIQUOR LAWS', 0.0050747921), ('LOITERING', 0.0047253072), ('RECOVERED VEHICLE', 0.0045913667)]\n",
      "[('RUNAWAY', 0.018371724), ('SEX OFFENSES FORCIBLE', 0.016582772), ('VEHICLE THEFT', 0.014349722), ('FRAUD', 0.013928068), ('MISSING PERSON', 0.013924303), ('BURGLARY', 0.01377563), ('SECONDARY CODES', 0.013284528), ('VANDALISM', 0.012490584), ('FORGERY/COUNTERFEITING', 0.012105169), ('KIDNAPPING', 0.01149694)]\n",
      "[('FRAUD', 0.020855563), ('FORGERY/COUNTERFEITING', 0.019319382), ('EMBEZZLEMENT', 0.018094499), ('SEX OFFENSES FORCIBLE', 0.015223335), ('TRESPASS', 0.013438686), ('BAD CHECKS', 0.01330398), ('BURGLARY', 0.012498548), ('SECONDARY CODES', 0.011144218), ('STOLEN PROPERTY', 0.011113664), ('KIDNAPPING', 0.010372542)]\n",
      "34904\n",
      "175610\n",
      "The accuracy is 19.87586%.\n"
     ]
    }
   ],
   "source": [
    "#Accuracy testing using predict_output_word- Gensim \n",
    "\n",
    "Counter=0 \n",
    "Score=0\n",
    "for i in range(0,len(TestSentences)):\n",
    "    prediction=model.predict_output_word(TestSentences[i])\n",
    "    Counter=Counter+1  \n",
    "    if i==1:\n",
    "        print (prediction) \n",
    "    if i==1000:\n",
    "        print (prediction) \n",
    "    if i==20000: \n",
    "        print (prediction)  \n",
    "    for j in range(len(prediction)):\n",
    "        P=prediction[j]\n",
    "        if (P[0]==(test['Category'].iloc[i])): \n",
    "            Score=Score+1\n",
    "            if i==1: \n",
    "                print (test['Category'].iloc[i])   \n",
    "print (Score) \n",
    "print (Counter) \n",
    "SampleSize=len(test['Category'])\n",
    "Accuracy= (Score/SampleSize)*100 #Accuracy score is generated by dividing the number of matches by the number of cases \n",
    "Accuracy= \"{0:.5f}\".format(Accuracy)\n",
    "Output = \"The accuracy is \" + Accuracy + \"%.\" \n",
    "print (Output)            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Accuracy testing using model.score()  \n",
    "\n",
    "model.score(['VIOLENT NORTHERN 23:53'.split()]) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-09-10 13:03:56,374 : INFO : scoring sentences with 3 workers on 1512 vocabulary and 300 features, using sg=1 hs=1 sample=0.001 and negative=5\n",
      "2017-09-10 13:03:56,376 : INFO : reached end of input; waiting to finish 1 outstanding jobs\n",
      "2017-09-10 13:03:56,378 : INFO : scoring 1 sentences took 0.0s, 386 sentences/s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([-23.42593193], dtype=float32)"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.score(['VIOLENT CENTRAL 23:00'.split()]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-09-10 13:42:49,010 : INFO : scoring sentences with 3 workers on 1512 vocabulary and 300 features, using sg=1 hs=1 sample=0.001 and negative=5\n",
      "2017-09-10 13:42:49,013 : INFO : reached end of input; waiting to finish 1 outstanding jobs\n",
      "2017-09-10 13:42:49,014 : INFO : scoring 1 sentences took 0.0s, 471 sentences/s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([ 0.], dtype=float32)"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.score(['CRIME IS BAD'.split()]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7964422806\n",
      "1.0\n",
      "0.42551629363\n",
      "0.94444549444\n"
     ]
    }
   ],
   "source": [
    "#Cosine similarity checks\n",
    "\n",
    "print (model.similarity('LARCENY/THEFT', 'KIDNAPPING')) \n",
    "print (model.similarity('FRAUD', 'FRAUD')) \n",
    "print (model.similarity('ARSON', 'FRAUD')) \n",
    "print (model.similarity('EMBEZZLEMENT', 'FRAUD')) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
